{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K fold cross validation **"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mnist = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntest_mnist = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\ntrain_mnist = train_mnist.values\ntest_mnist = test_mnist.values","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\ndef cross_valid_score(k_fold,train):\n   # k_fold = 4\n   # df = train_mnist\n    val_size = train.shape[0]//k_fold\n    for i in range(k_fold):\n        val_data = train[i*val_size:(i+1)*val_size,1:]\n        train_data = np.concatenate((train[:i*val_size,1:],train[(i+1)*val_size:,1:]),axis = 0)\n        #OnehotEncoding the labels\n        x = np.zeros((train.shape[0],10))\n        for j,num in enumerate(train[:,0]):\n            x[j,num] = 1\n        val_labels =x[i*val_size:(i+1)*val_size,:]\n        train_labels = np.concatenate((x[:i*val_size,:],x[(i+1)*val_size:,:]),axis = 0)\n        model = models.Sequential()\n        model.add(layers.Dense(512,input_shape = (784,),activation = 'relu'))\n        model.add(layers.Dense(256,activation = 'relu'))\n        model.add(layers.Dense(10,activation = 'softmax'))\n        print(train_data.shape,train_labels.shape,val_data.shape,val_labels.shape)\n        #print(x)\n        model.compile(loss = 'categorical_crossentropy',optimizer = optimizers.Adam(),metrics = ['accuracy'])\n        histy = model.fit(train_data,train_labels,epochs = 20,batch_size = 128,validation_data = (val_data,val_labels))\n        print(histy.history)\n        #OnehotEncoding the labels\n        \ncross_valid_score(4,train_mnist)","execution_count":33,"outputs":[{"output_type":"stream","text":"(45000, 784) (45000, 10) (15000, 784) (15000, 10)\nTrain on 45000 samples, validate on 15000 samples\nEpoch 1/20\n45000/45000 [==============================] - 4s 90us/step - loss: 2.8293 - accuracy: 0.8903 - val_loss: 0.6761 - val_accuracy: 0.9142\nEpoch 2/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.3543 - accuracy: 0.9454 - val_loss: 0.3989 - val_accuracy: 0.9399\nEpoch 3/20\n45000/45000 [==============================] - 4s 87us/step - loss: 0.1860 - accuracy: 0.9621 - val_loss: 0.2822 - val_accuracy: 0.9507\nEpoch 4/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.1244 - accuracy: 0.9726 - val_loss: 0.3611 - val_accuracy: 0.9448\nEpoch 5/20\n45000/45000 [==============================] - 4s 87us/step - loss: 0.1279 - accuracy: 0.9723 - val_loss: 0.3361 - val_accuracy: 0.9519\nEpoch 6/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.1091 - accuracy: 0.9753 - val_loss: 0.4463 - val_accuracy: 0.9369\nEpoch 7/20\n45000/45000 [==============================] - 4s 90us/step - loss: 0.0855 - accuracy: 0.9779 - val_loss: 0.2970 - val_accuracy: 0.9539\nEpoch 8/20\n45000/45000 [==============================] - 4s 88us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.2396 - val_accuracy: 0.9624\nEpoch 9/20\n45000/45000 [==============================] - 4s 88us/step - loss: 0.0800 - accuracy: 0.9814 - val_loss: 0.2953 - val_accuracy: 0.9537\nEpoch 10/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0750 - accuracy: 0.9817 - val_loss: 0.2698 - val_accuracy: 0.9631\nEpoch 11/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0959 - accuracy: 0.9794 - val_loss: 0.2557 - val_accuracy: 0.9595\nEpoch 12/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0791 - accuracy: 0.9808 - val_loss: 0.2085 - val_accuracy: 0.9681\nEpoch 13/20\n45000/45000 [==============================] - 4s 83us/step - loss: 0.0750 - accuracy: 0.9824 - val_loss: 0.2744 - val_accuracy: 0.9642\nEpoch 14/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0770 - accuracy: 0.9815 - val_loss: 0.2551 - val_accuracy: 0.9669\nEpoch 15/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0620 - accuracy: 0.9843 - val_loss: 0.2222 - val_accuracy: 0.9645\nEpoch 16/20\n45000/45000 [==============================] - 4s 87us/step - loss: 0.0633 - accuracy: 0.9856 - val_loss: 0.1973 - val_accuracy: 0.9671\nEpoch 17/20\n45000/45000 [==============================] - 4s 87us/step - loss: 0.0520 - accuracy: 0.9876 - val_loss: 0.2571 - val_accuracy: 0.9635\nEpoch 18/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0568 - accuracy: 0.9860 - val_loss: 0.2484 - val_accuracy: 0.9657\nEpoch 19/20\n45000/45000 [==============================] - 4s 84us/step - loss: 0.0598 - accuracy: 0.9853 - val_loss: 0.2527 - val_accuracy: 0.9649\nEpoch 20/20\n45000/45000 [==============================] - 4s 84us/step - loss: 0.0637 - accuracy: 0.9844 - val_loss: 0.2011 - val_accuracy: 0.9705\n{'val_loss': [0.6761219280640284, 0.39885915603637695, 0.28224948643048603, 0.36113249979068834, 0.3361202665215048, 0.44625552621682485, 0.2969778967132171, 0.23957569509378324, 0.29530870808386245, 0.2697717394909511, 0.25565628531624873, 0.20850413081595132, 0.274376876193285, 0.2550561283121196, 0.22222240798746545, 0.1972859430571397, 0.25709337484762074, 0.24841254642307758, 0.25265395372907323, 0.20105853457408182], 'val_accuracy': [0.9142000079154968, 0.9398666620254517, 0.9506666660308838, 0.9448000192642212, 0.9518666863441467, 0.9368666410446167, 0.9539333581924438, 0.9624000191688538, 0.9536666870117188, 0.9630666375160217, 0.9594666957855225, 0.9681333303451538, 0.9642000198364258, 0.966866672039032, 0.9645333290100098, 0.9671333432197571, 0.963533341884613, 0.9657333493232727, 0.9649333357810974, 0.9705333113670349], 'loss': [2.829264621141222, 0.3543443362103568, 0.18597586182852585, 0.1244435423175494, 0.1279078548848629, 0.10914937908351421, 0.08549430934555001, 0.07018733488404089, 0.07995094789324535, 0.07504983173857133, 0.09592852646302846, 0.07912877968582842, 0.07496852893357475, 0.07703723126558794, 0.06201734781323208, 0.06325779273298879, 0.05200489304082261, 0.056843480843553944, 0.059788057162271195, 0.06368759079438945], 'accuracy': [0.89033335, 0.9454, 0.9620889, 0.9726, 0.9722667, 0.97528887, 0.9778889, 0.9822222, 0.9813778, 0.9817111, 0.9794222, 0.98075557, 0.9824, 0.9815111, 0.9843111, 0.98557776, 0.9875778, 0.98604447, 0.9852667, 0.9843778]}\n(45000, 784) (45000, 10) (15000, 784) (15000, 10)\nTrain on 45000 samples, validate on 15000 samples\nEpoch 1/20\n45000/45000 [==============================] - 4s 100us/step - loss: 2.8710 - accuracy: 0.8934 - val_loss: 0.6114 - val_accuracy: 0.9271\nEpoch 2/20\n45000/45000 [==============================] - 4s 97us/step - loss: 0.3477 - accuracy: 0.9497 - val_loss: 0.4168 - val_accuracy: 0.9418\nEpoch 3/20\n45000/45000 [==============================] - 4s 97us/step - loss: 0.1858 - accuracy: 0.9655 - val_loss: 0.3416 - val_accuracy: 0.9532\nEpoch 4/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.1435 - accuracy: 0.9723 - val_loss: 0.3736 - val_accuracy: 0.9484\nEpoch 5/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.1288 - accuracy: 0.9739 - val_loss: 0.3683 - val_accuracy: 0.9504\nEpoch 6/20\n45000/45000 [==============================] - 4s 99us/step - loss: 0.1038 - accuracy: 0.9788 - val_loss: 0.3064 - val_accuracy: 0.9575\nEpoch 7/20\n45000/45000 [==============================] - 4s 100us/step - loss: 0.0938 - accuracy: 0.9797 - val_loss: 0.3791 - val_accuracy: 0.9478\nEpoch 8/20\n45000/45000 [==============================] - 4s 98us/step - loss: 0.1003 - accuracy: 0.9790 - val_loss: 0.3056 - val_accuracy: 0.9585\nEpoch 9/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.0863 - accuracy: 0.9812 - val_loss: 0.3116 - val_accuracy: 0.9579\nEpoch 10/20\n45000/45000 [==============================] - 4s 94us/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.3106 - val_accuracy: 0.9550\nEpoch 11/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.0813 - accuracy: 0.9825 - val_loss: 0.3195 - val_accuracy: 0.9559\nEpoch 12/20\n45000/45000 [==============================] - 4s 94us/step - loss: 0.0616 - accuracy: 0.9852 - val_loss: 0.3003 - val_accuracy: 0.9611\nEpoch 13/20\n45000/45000 [==============================] - 4s 93us/step - loss: 0.0825 - accuracy: 0.9827 - val_loss: 0.2942 - val_accuracy: 0.9614\nEpoch 14/20\n45000/45000 [==============================] - 4s 93us/step - loss: 0.0713 - accuracy: 0.9836 - val_loss: 0.3129 - val_accuracy: 0.9554\nEpoch 15/20\n45000/45000 [==============================] - 4s 97us/step - loss: 0.0571 - accuracy: 0.9858 - val_loss: 0.3313 - val_accuracy: 0.9593\nEpoch 16/20\n45000/45000 [==============================] - 4s 96us/step - loss: 0.0576 - accuracy: 0.9860 - val_loss: 0.2679 - val_accuracy: 0.9628\nEpoch 17/20\n45000/45000 [==============================] - 4s 98us/step - loss: 0.0615 - accuracy: 0.9859 - val_loss: 0.2871 - val_accuracy: 0.9639\nEpoch 18/20\n45000/45000 [==============================] - 4s 97us/step - loss: 0.0750 - accuracy: 0.9840 - val_loss: 0.3238 - val_accuracy: 0.9633\nEpoch 19/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.0670 - accuracy: 0.9853 - val_loss: 0.2634 - val_accuracy: 0.9637\nEpoch 20/20\n45000/45000 [==============================] - 4s 94us/step - loss: 0.0414 - accuracy: 0.9899 - val_loss: 0.2950 - val_accuracy: 0.9647\n{'val_loss': [0.611414767519633, 0.4168340937892596, 0.34155336328148844, 0.373624287228783, 0.3683108493705591, 0.3064377224216859, 0.3790694697658221, 0.3055692845662435, 0.31161893341143926, 0.3105608399947484, 0.3194972170909246, 0.30031802721673156, 0.29415438804604077, 0.3129456135749817, 0.33133339967926345, 0.2679297951420148, 0.2871114963334054, 0.323809281818072, 0.2634003602909545, 0.29503290860652925], 'val_accuracy': [0.927133321762085, 0.9417999982833862, 0.9531999826431274, 0.9484000205993652, 0.9503999948501587, 0.9574666619300842, 0.9477999806404114, 0.9585333466529846, 0.9579333066940308, 0.9549999833106995, 0.9559333324432373, 0.9611333608627319, 0.9613999724388123, 0.9553999900817871, 0.9593333601951599, 0.9628000259399414, 0.9639333486557007, 0.9632666707038879, 0.9637333154678345, 0.964733362197876], 'loss': [2.8709795111338297, 0.34771650460561115, 0.185778068696128, 0.1434657466325495, 0.1287572570393483, 0.10381730475665794, 0.09383117305446002, 0.10027888495259815, 0.0863054126115309, 0.0919339884567178, 0.08134708120889134, 0.061613574715165625, 0.08253744130416049, 0.07134718663891157, 0.05708750782927705, 0.05759870906654332, 0.06148318434705337, 0.07502997927375965, 0.0670212589489296, 0.04142673119107882], 'accuracy': [0.89342225, 0.9496889, 0.9655111, 0.9722667, 0.9738889, 0.97875553, 0.97973335, 0.9790222, 0.9811778, 0.98035556, 0.9824889, 0.98524445, 0.9826889, 0.9836444, 0.9858222, 0.98597777, 0.98586667, 0.9840222, 0.9853111, 0.9898889]}\n(45000, 784) (45000, 10) (15000, 784) (15000, 10)\n","name":"stdout"},{"output_type":"stream","text":"Train on 45000 samples, validate on 15000 samples\nEpoch 1/20\n45000/45000 [==============================] - 4s 91us/step - loss: 2.6053 - accuracy: 0.8963 - val_loss: 0.6560 - val_accuracy: 0.9264\nEpoch 2/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.3651 - accuracy: 0.9489 - val_loss: 0.4565 - val_accuracy: 0.9401\nEpoch 3/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.1951 - accuracy: 0.9650 - val_loss: 0.3857 - val_accuracy: 0.9441\nEpoch 4/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.1354 - accuracy: 0.9726 - val_loss: 0.2802 - val_accuracy: 0.9569\nEpoch 5/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.1010 - accuracy: 0.9785 - val_loss: 0.4050 - val_accuracy: 0.9497\nEpoch 6/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.3114 - val_accuracy: 0.9603\nEpoch 7/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0939 - accuracy: 0.9796 - val_loss: 0.3140 - val_accuracy: 0.9590\nEpoch 8/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0971 - accuracy: 0.9796 - val_loss: 0.3190 - val_accuracy: 0.9535\nEpoch 9/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0946 - accuracy: 0.9788 - val_loss: 0.2936 - val_accuracy: 0.9597\nEpoch 10/20\n45000/45000 [==============================] - 4s 93us/step - loss: 0.0783 - accuracy: 0.9826 - val_loss: 0.2900 - val_accuracy: 0.9583\nEpoch 11/20\n45000/45000 [==============================] - 4s 94us/step - loss: 0.0784 - accuracy: 0.9813 - val_loss: 0.3445 - val_accuracy: 0.9513\nEpoch 12/20\n45000/45000 [==============================] - 4s 89us/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.2686 - val_accuracy: 0.9641\nEpoch 13/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0667 - accuracy: 0.9850 - val_loss: 0.2759 - val_accuracy: 0.9629\nEpoch 14/20\n45000/45000 [==============================] - 4s 88us/step - loss: 0.0657 - accuracy: 0.9846 - val_loss: 0.2637 - val_accuracy: 0.9649\nEpoch 15/20\n45000/45000 [==============================] - 4s 87us/step - loss: 0.0700 - accuracy: 0.9834 - val_loss: 0.2528 - val_accuracy: 0.9643\nEpoch 16/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0732 - accuracy: 0.9827 - val_loss: 0.2598 - val_accuracy: 0.9615\nEpoch 17/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0756 - accuracy: 0.9823 - val_loss: 0.2337 - val_accuracy: 0.9668\nEpoch 18/20\n45000/45000 [==============================] - 4s 86us/step - loss: 0.0523 - accuracy: 0.9877 - val_loss: 0.2815 - val_accuracy: 0.9627\nEpoch 19/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 0.2666 - val_accuracy: 0.9667\nEpoch 20/20\n45000/45000 [==============================] - 4s 85us/step - loss: 0.0523 - accuracy: 0.9875 - val_loss: 0.2883 - val_accuracy: 0.9645\n{'val_loss': [0.6559693819880485, 0.45649189883470537, 0.3856791995604833, 0.28019078671137493, 0.4049815519014994, 0.31140350925259797, 0.3140390956646452, 0.3189827556959353, 0.2936271840234598, 0.29001340767145156, 0.3445400840441386, 0.26864299265742303, 0.275930281317234, 0.26372676866302885, 0.25275152897238734, 0.2597533382376035, 0.23371622435276707, 0.28151160542964937, 0.2665885008189827, 0.28827803930441537], 'val_accuracy': [0.9264000058174133, 0.9400666952133179, 0.9440666437149048, 0.9568666815757751, 0.949733316898346, 0.9603333473205566, 0.9589999914169312, 0.9534666538238525, 0.9597333073616028, 0.9582666754722595, 0.9512666463851929, 0.9640666842460632, 0.9628666639328003, 0.9648666381835938, 0.9642666578292847, 0.9614666700363159, 0.9667999744415283, 0.9626666903495789, 0.9666666388511658, 0.9644666910171509], 'loss': [2.6053044984022775, 0.3651121430873871, 0.19510194491611588, 0.13537360333278775, 0.1010228906745712, 0.09725131534404224, 0.09390539137356811, 0.09707108994258774, 0.09455595948133204, 0.07830370400316185, 0.07842815347992711, 0.08287339887287881, 0.06671663212602337, 0.06569334625096784, 0.06999197730968396, 0.07319532472255329, 0.07562116784436836, 0.052308268632284466, 0.05890956511042184, 0.052312440471930635], 'accuracy': [0.8963111, 0.94886667, 0.96504444, 0.9725556, 0.9785333, 0.9786889, 0.97962224, 0.9796, 0.97882223, 0.98264444, 0.9812667, 0.98095554, 0.985, 0.98462224, 0.9834, 0.9826667, 0.98233336, 0.9876889, 0.9854444, 0.9875111]}\n(45000, 784) (45000, 10) (15000, 784) (15000, 10)\nTrain on 45000 samples, validate on 15000 samples\nEpoch 1/20\n45000/45000 [==============================] - 4s 94us/step - loss: 2.7139 - accuracy: 0.8968 - val_loss: 0.6817 - val_accuracy: 0.9313\nEpoch 2/20\n45000/45000 [==============================] - 4s 92us/step - loss: 0.3980 - accuracy: 0.9511 - val_loss: 0.4593 - val_accuracy: 0.9469\nEpoch 3/20\n45000/45000 [==============================] - 4s 92us/step - loss: 0.2261 - accuracy: 0.9643 - val_loss: 0.4410 - val_accuracy: 0.9473\nEpoch 4/20\n45000/45000 [==============================] - 4s 90us/step - loss: 0.1625 - accuracy: 0.9723 - val_loss: 0.3850 - val_accuracy: 0.9529\nEpoch 5/20\n45000/45000 [==============================] - 4s 96us/step - loss: 0.1513 - accuracy: 0.9745 - val_loss: 0.4395 - val_accuracy: 0.9552\nEpoch 6/20\n45000/45000 [==============================] - 4s 96us/step - loss: 0.1456 - accuracy: 0.9750 - val_loss: 0.4012 - val_accuracy: 0.9552\nEpoch 7/20\n45000/45000 [==============================] - 4s 93us/step - loss: 0.1254 - accuracy: 0.9775 - val_loss: 0.4025 - val_accuracy: 0.9541\nEpoch 8/20\n45000/45000 [==============================] - 4s 92us/step - loss: 0.1154 - accuracy: 0.9795 - val_loss: 0.3564 - val_accuracy: 0.9588\nEpoch 9/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.1095 - accuracy: 0.9792 - val_loss: 0.3136 - val_accuracy: 0.9629\nEpoch 10/20\n45000/45000 [==============================] - 4s 90us/step - loss: 0.0710 - accuracy: 0.9853 - val_loss: 0.3343 - val_accuracy: 0.9640\nEpoch 11/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.1011 - accuracy: 0.9819 - val_loss: 0.3284 - val_accuracy: 0.9592\nEpoch 12/20\n45000/45000 [==============================] - 4s 90us/step - loss: 0.0838 - accuracy: 0.9828 - val_loss: 0.2906 - val_accuracy: 0.9635\nEpoch 13/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.0639 - accuracy: 0.9859 - val_loss: 0.2777 - val_accuracy: 0.9613\nEpoch 14/20\n45000/45000 [==============================] - 4s 92us/step - loss: 0.0776 - accuracy: 0.9838 - val_loss: 0.2746 - val_accuracy: 0.9642\nEpoch 15/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.0560 - accuracy: 0.9874 - val_loss: 0.3056 - val_accuracy: 0.9625\nEpoch 16/20\n45000/45000 [==============================] - 4s 91us/step - loss: 0.0786 - accuracy: 0.9833 - val_loss: 0.2793 - val_accuracy: 0.9683\nEpoch 17/20\n45000/45000 [==============================] - 4s 96us/step - loss: 0.0776 - accuracy: 0.9844 - val_loss: 0.3497 - val_accuracy: 0.9640\nEpoch 18/20\n45000/45000 [==============================] - 4s 95us/step - loss: 0.0659 - accuracy: 0.9849 - val_loss: 0.2500 - val_accuracy: 0.9681\nEpoch 19/20\n45000/45000 [==============================] - 5s 101us/step - loss: 0.0590 - accuracy: 0.9871 - val_loss: 0.2606 - val_accuracy: 0.9655\nEpoch 20/20\n45000/45000 [==============================] - 4s 93us/step - loss: 0.0547 - accuracy: 0.9876 - val_loss: 0.2905 - val_accuracy: 0.9652\n{'val_loss': [0.6817175705005725, 0.459344293628571, 0.4410217372247251, 0.38503677709144685, 0.4395489525043716, 0.40122362518310256, 0.4024656080901623, 0.356435934416453, 0.31355753442571926, 0.3343227778077126, 0.328409403526783, 0.2906076976338918, 0.2776613729710798, 0.2746205693977298, 0.30560172741686303, 0.2792802347417113, 0.3496770256290833, 0.24996457293758284, 0.2606295651279545, 0.2904529699576], 'val_accuracy': [0.9313333630561829, 0.9469333291053772, 0.9473333358764648, 0.9528666734695435, 0.9552000164985657, 0.9552000164985657, 0.9540666937828064, 0.9588000178337097, 0.9628666639328003, 0.9639999866485596, 0.9592000246047974, 0.9634666442871094, 0.9613333344459534, 0.9642000198364258, 0.9625333547592163, 0.9683333039283752, 0.9639999866485596, 0.9681333303451538, 0.9654666781425476, 0.9652000069618225], 'loss': [2.713859464899699, 0.3980378421889411, 0.22606631082031461, 0.1624643994493617, 0.15130091074734098, 0.14556978624181616, 0.1254313687274129, 0.11544146485833658, 0.10954410928281594, 0.07097474360794036, 0.10107864479666782, 0.08380815266561177, 0.06386056489079363, 0.07760225374317832, 0.056011351913089556, 0.07863119823531144, 0.07764962155932767, 0.06587052985264195, 0.05899630478148659, 0.05465236512986012], 'accuracy': [0.8968, 0.9510667, 0.96426666, 0.9723333, 0.9744667, 0.9749778, 0.9775111, 0.9795111, 0.97922224, 0.9853333, 0.98193336, 0.98282224, 0.9859333, 0.9838222, 0.98735553, 0.9833111, 0.98444444, 0.9848667, 0.9871333, 0.9875778]}\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}